《python神经网络编程》读书笔记

# 之一

大约三天读完，这本书浅显易懂，非常适合入门，只有权重调整值的推导过程看得不是很透彻。
## 基本概念
神经网络也是机器学习的一种实现，可以应用在有监督学习和无监督学习，因为中间可以有较多层，所以属于深度学习方法。

神经网络的名字很唬人，其实概念挺朴素的，是由含一个输入层一个输出层和若干隐藏层构成的有向无环图（这名字也唬人），看图像一目了然，为啥叫隐藏层呢，就是因为和输入输出没关系，看不见，有点儿神秘。每层的每个结点借助生物的概念称为神经元，各层之间神经元相互链接。

![](http://ww1.sinaimg.cn/mw690/780b940aly1frpn9bdowqj20un0u0tai.jpg)

算法训练包含两个阶段：输入向输出传送叫前向馈送信号，输出向输入传送叫反向误差传播。把输入前馈计算得到输出，把输出与目标值比对计算误差，把误差反向传播修正链接权重。具体过程是：

1. “输入层与隐藏层之间的链接权重”与“输入信号”加权求和，“和值”通过神经元函数（通常是阶跃函数）运算得到隐藏层的结果。
2. 用与第一步相同的过程计算出输出层的结果。
3. 目标值-输出值=误差。
4. 将误差按权重反向传播给隐藏层。
5. 用梯度下降法最小化误差，计算出误差调整值，初始误差+误差调整值=训练结果。

### 注意点
- 初始权重未知，为了避免落入错误的山谷，随机选取多个起始点（初始权重）。

- 根据调整应用在信号上的神经元函数的斜率来调整权重。

- 梯度下降法最小化误差函数。

- 训练过程就是调整权重的过程，初始权重的设定要注意避免网络饱和。初始权重过大容易导致网络饱和，初始权重为0或者相等将导致丧失学习能力。

- 输入信号通常取值范围是0.01 ~ 0.99或-1.0 ~ 1.0，一个比较合适的输出取值范围0.01 ~ 0.99。

## 问题
- 1.12节反向传播误差到更多层中，最后一张图将误差传播到了输入层，这给我造成了困惑，想了大半天，因为在后面调整误差的时候只用到了隐藏层和输出层的误差，其实在三层的网络中，只需要用输出层误差计算Who和用隐藏层误差计算Wih，计算输入层的误差其实没有用，书中应该是借用这一步推导更明确一下传播误差的方法。

- 2.4.4节wih初始化时正态分布的标准差取1/sqrt(传入链接数目)，代码中隐藏层传入链接数目用hnodes，输出层传入链接数目用onodes，我认为传入链接数目应该是上一层的结点数，所以分别应该是inodes和hnodes。

- 训练时cpu使用率40%，跑了一会以后升高到60%，临近计算结束又降到40%，不是一直跑满。

## 训练结果
MNIST手写数字识别

世代 | 隐藏层 | 隐藏层结点数 | 学习率 | 识别率 | 训练时长(s)
---|---|---|---|---|---
1 | 1 | 100 | 0.1 | 0.9479 | 24.0102
1 | 1 | 100 | 0.2 | **0.9518** | 25.4991
1 | 1 | 100 | 0.3 | 0.9443 | 26.0787
1 | 1 | 100 | 0.6 | 0.9209 | 24.9883
1 | 1 | 10 | 0.2 | **0.8495** | 11.4656
1 | 1 | 200 | 0.2 | 0.9558 | 97.4185
2 | 1 | 200 | 0.2 | 0.9574 | 49.0803
3 | 1 | 200 | 0.2 | 0.9602 | 78.7243
4 | 1 | 200 | 0.2 | 0.959 | 104.7202
5 | 1 | 200 | 0.2 | **0.9627** |146.9687
6 | 1 | 200 | 0.2 | 0.9577 | 162.4879

# 之二

## 更多隐藏层

书中分别对比了不同学习率，不同隐藏层结点数和不同训练世代的模型学习效果，没有对比多隐藏层的模型，我自己添加了一层隐藏层的代码，得出的训练结果如下：

世代 | 隐藏层 | 隐藏层结点数 | 学习率 | 识别率 | 训练时长(s)
---|---|---|---|---|---
1 | 2 | 10*10 | 0.2 | 0.7677 | 11.5368
1 | 2 | 20*20 | 0.2 | 0.8066 | 17.0215
1 | 2 | 30*30 | 0.2 | 0.8442 | 17.4176
1 | 2 | 20*30 | 0.2 | **0.7984** | 16.7845
1 | 2 | 30*20 | 0.2 | 0.8412 | 17.7463
1 | 2 | 50*50 | 0.2 | 0.8471 | 20.3632
1 | 2 | 100*100 | 0.2 | 0.8496 | 31.0611
2 | 2 | 100*100 | 0.2 | 0.8635 | 65.3597

可见多一层隐藏层学习想过不但没有提高，反而下降了。

相同训练世代相同学习率的识别率：

10 * 10 < 20 * 30 < 20 * 20 < 30 * 20 < 30 * 30 < 50 * 50

[代码](https://github.com/YngwieWang/NeuralNetwork/blob/master/annMnist_4layer.ipynb)

## 看看训练集的数字图像

把训练集的数组转换成图像，大概浏览一下手写的样子

![](http://ww1.sinaimg.cn/large/780b940aly1frqsx8rpxvj20le0j7ac7.jpg)

转换代码：
```
import numpy as np
import matplotlib.pyplot as plt


with open(r'mnist/mnist_train.csv', 'r') as datafile:
    line = datafile.readline()
    i = 1
    while line and i < 50:
        all_values = line.split(',')
        label = all_values[0]
        img_array = np.asfarray(all_values[1:]).reshape((28, 28))
        # plt.axis('off')
        plt.imshow(img_array, cmap='Greys')
        filename = 'mnist/mnist_images/test' + str(i) +\
                   '_' + label + '.png'
        plt.savefig(filename)
        i += 1
        line = datafile.readline()
```

## 更多的训练数据

MNIST有60,000条训练数据，书上为了获得更多的训练数据把每一条训练数据的图像分别顺时针、逆时针旋转了10度，这样就添加了两倍的训练样本。

世代 | 隐藏层 | 隐藏层结点数 | 学习率 | 识别率 | 训练时长(s) | 是否训练旋转数据
---|---|---|---|---|---|---
1 | 1 | 100 | 0.2 | 0.9518 | 25.4991 | 否
1 | 1 | 100 | 0.2 | 0.9471 | 70.7045 | 是
1 | 1 | 100 | 0.1 | 0.9503 | 25.7134 | 否
1 | 1 | 100 | 0.1 | 0.9544 | 70.7045 | 是
1 | 1 | 100 | 0.01 | 0.9131 | 26.4683 | 否
1 | 1 | 100 | 0.01 | 0.9329 | 72.5362 | 是
1 | 1 | 100 | 0.05 | 0.9443 | 27.1351 | 否
1 | 1 | 100 | 0.05 | 0.9519 | 73.1557 | 是
1 | 1 | 200 | 0.01 | 0.9065 | 97.4234 | 否
1 | 1 | 200 | 0.01 | 0.9338 | 296.3523 | 是
10 | 1 | 200 | 0.01 | **0.9677** | 1115.5962 | 否
10 | 1 | 200 | 0.01 | **0.9777** | 2890.7095 | 是



当学习率为0.2时，加入旋转训练数据的模型识别率反倒更低，将学习率减小为0.01以后增加旋转数据可以提高识别率，通过学习率0.01和0.05两个模型进一步判断学习率越小，增加旋转训练数据带来的学习了提高越多。但问题是很明显**训练样本增多反而导致识别率下降**。于是我怀疑我的代码有没有问题，下载了作者的代码跑，他是200个隐藏层结点、0.01的学习率跑了10个世代，github上他代码跑的结果是0.9754，我下载下来跑的是0.9779，然后我把我的代码改成一样的跑法用了2890.709569秒合48分钟，识别率是0.9777，看来没问题。然后我对比了一下10世代不用旋转数据的，识别率是0.9677，看来大样本在多世代的学习后效果才显现，另外正如书上说的，样本量大了以后可以采用更小、更谨慎的学习步长，因此将学习率减少到0.01。

另外我对比了一下我的代码和作者代码的执行效率，100个隐藏层结点0.2学习率1世代我的代码跑了71.5秒，作者的跑了74秒。


## 问题
上一篇笔记中提到初始化权重的时候正态分布方差使用的是传入链接数也就是上一层结点数，而书上用的是当前结点数，我在看github上的代码时作者已经修正为上一层结点数了。

# 之三

## 识别自己写的数字
下面到了好玩儿的部分。用包含了旋转图像角度的数据训练好的200个隐藏层结点、10世代的模型，识别率为0.9771，识别我家三口写的0-9共30个数字，故意写得乱一点。正确识别了12个，识别率只有40%，在调节过程中我发现数字在图片中的位置和图片的对比度都会影响识别效果，我把测试集的对比度+0.1（值域是0.01 ~ 0.99）识别对了15个，+0.2，识别对了18个，对比度打满，识别对了18个。然后我规规矩矩写了10个数字，除了9以外都正确识别了，重写了一个圆更大的9识别正确了。

图片转换成数组用于识别
```
import numpy as np
import matplotlib.pyplot as plt
import scipy.misc
from PIL import Image


root = r'D:\pyFiles\365venv\nnp\testwang'
test_data = []
right = 0

for dirpath, dirnames, filenames in os.walk(root):
    for filename in filenames:
        # print(filepath)
        if filename != 'all.jpg':
            label = filename.split('.')[0][-1]
            img = Image.open(r'testwang/' + filename)

            # 将图像转换为灰度模式
            img = img.convert('L')
            img_array = np.array(img)

            # plt.imshow(img_array, cmap='Greys')
            # 此时图像的黑白和训练样本的是颠倒的，需要反过来
            img_array = 255.0 - img_array
            img_array = img_array / 255.0 * 0.99 + 0.01
            img_array = img_array.flatten()

            res = n.query(img_array).argmax()
            print(label, res)
            if label == str(res):
                right += 1
    print(right)
```

## 更多的训练数据

书中用旋转图像的方法增加了训练数据，我能想到的还可以移动图片位置，根据识别我手写数字的经验还有调整图片对比度的方法可以再增加一些训练数据，看看训练效果能不能再提高。
```
# 训练
from time import perf_counter as pc
start = pc()
for _ in range(10):
    for record in training_data_list:
        all_values = record.split(',')
        # inputs是一维数组
        inputs = np.asfarray(all_values[1:]) / 255.0 * 0.99 + 0.01
        targets = np.zeros(output_nodes) + 0.01
        targets[int(all_values[0])] = 0.99
        n.train(inputs, targets)
        # imputs_matrix是28 * 28矩阵
        imputs_matrix = inputs.reshape(28, 28)

        # 左移一个像素
        img_left = np.zeros((28, 28)) + 0.01
        img_left[:, :-1] = imputs_matrix[:, 1:]
        n.train(img_left.ravel(), targets)
        # 右移一个像素
        img_right = np.zeros((28, 28)) + 0.01
        img_right[:, 1:] = imputs_matrix[:, :-1]
        n.train(img_right.ravel(), targets)
        # 上移一个像素
        img_up = np.zeros((28, 28)) + 0.01
        img_up[:-1, :] = imputs_matrix[1:, :]
        n.train(img_up.ravel(), targets)
        # 下移一个像素
        img_down = np.zeros((28, 28)) + 0.01
        img_down[1:, :] = imputs_matrix[:-1, :]
        n.train(img_down.ravel(), targets)
        # 加0.2对比度
        img_array = inputs
        for i in range(len(img_array)):
            if img_array[i] != 0.01:
                img_array[i] += 0.2
            if img_array[i] > 0.99:
                img_array[i] = 0.99
        n.train(img_array, targets)
        # 减0.1对比度
        img_array = inputs
        for i in range(len(img_array)):
            if img_array[i] != 0.01:
                img_array[i] -= 0.1
            if img_array[i] < 0.011:
                img_array[i] = 0.011
        n.train(img_array, targets)

        # 顺时针旋转10度
        img_plus10 = scipy.ndimage.interpolation.rotate(imputs_matrix, 10, cval=0.01, order=1, reshape=False)
        n.train(img_plus10.ravel(), targets)
        # 逆时针旋转10度
        img_minus10 = scipy.ndimage.interpolation.rotate(imputs_matrix, -10, cval=0.01, order=1, reshape=False)
        n.train(img_minus10.ravel(), targets)
```
我使用了200个隐藏层结点，学习率0.005，训练10世代，对MNIST原始数据、顺时针逆时针旋转10度、上下左右各移动1个像素和对比度增加0.2减少0.1共9套数据进行训练，耗时9010.42305秒，合两个半小时，得到识别率0.9783，虽然只提高了0.0004，而且增加的训练样本是否对这个提高有作用很难说，但是能进步一点还是挺高兴的。

然后接下来的鼓捣给我带来了惊喜，识别我家三口的手写准确率有了提升：

模型 | 增加对比度 | 识别率
---|---|---
MNIST+旋转| +0 | 12
MNIST+旋转| +0.1 | 15
MNIST+旋转| +0.2-0.5 | 18
MNIST+旋转| +0.6-0.7 | 17
MNIST+旋转| +0.8及以上 | 18
MNIST+旋转+平移+增减对比度| +0 | 12
MNIST+旋转+平移+增减对比度| +0.1 | 17
MNIST+旋转+平移+增减对比度| +0.2 | 19
MNIST+旋转+平移+增减对比度| +0.4 | 20
MNIST+旋转+平移+增减对比度| +0.5及以上 | 19

通过以上的测试我认为平移和调整对比度对于模型的训练时有意义的，同时我还发现不是对比度越大识别率越大。

#### 识别结果，红字为错误识别结果

![](http://ww1.sinaimg.cn/large/780b940aly1frtpe1u5taj20hs0e6759.jpg)

## 收获
书中说他在加入旋转训练数据后识别率到达0.9787，几乎到达98%，感觉很骄傲。而我在实测我的手写数字时识别率并不令人满意。我读书的时候就想到了平移图片增加训练样本，我在上一篇笔记中把数组转换成图片查看手写数字形状的时候注释了一行```# plt.axis('off')```，开始把坐标轴去掉是想更清楚地看数字形状，后来注释掉了就是特地为了看一下数字与边缘的距离，我看有些数字距离边缘只有一个像素，如果移动两个像素可能会比较严重地影响数字的形状。所以我在平移的时候只移动了一个像素。然后在测试我自己的手写样本时又发现识别率和对比度有关系，就加上了对增减了对比度的样本的训练。

训练时间从最初的24秒增加到了两个半小时，还可以再通过调整训练样本的参数继续增加训练集，但我感觉已经非常接近极限了，通过调整图片位置和对比度我感觉如果只是同一个训练样本变换位置和对比度就能训练出不同的结果，就应该在模型上想办法了，继续在训练样本上做文章意义不大了。对于这本书和这个模型暂时先学习到这里吧，看书用3天，自己扩展用了3天，把书读厚这个过程收获良多。

